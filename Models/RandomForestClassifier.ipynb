{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "for i in range(0,6):\n",
    "    filename=open('SampleNo.'+str(i),'rb')\n",
    "    samples.append(pickle.load(filename)) \n",
    "    filename.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>66635</th>\n",
       "      <th>66636</th>\n",
       "      <th>66637</th>\n",
       "      <th>66638</th>\n",
       "      <th>66639</th>\n",
       "      <th>66640</th>\n",
       "      <th>66641</th>\n",
       "      <th>66642</th>\n",
       "      <th>66643</th>\n",
       "      <th>66644</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>0.219468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.005629</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034420</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.024073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>0.094349</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>0.007298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.015210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>0.053086</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>0.150254</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.017615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  Class         1         2         3         4         5  \\\n",
       "4807  0.219468      2  0.000000  0.000000  0.000000  0.000018  0.000000   \n",
       "909   0.094349      5  0.000497  0.000524  0.000097  0.000162  0.002755   \n",
       "7649  0.007298      1  0.000497  0.000524  0.000193  0.000036  0.002755   \n",
       "3903  0.053086      9  0.001490  0.001748  0.000870  0.000126  0.022039   \n",
       "5385  0.150254      3  0.002732  0.002273  0.001353  0.000198  0.022039   \n",
       "\n",
       "             6         7         8  ...     66635     66636     66637  \\\n",
       "4807  0.000000  0.000000  0.000000  ...  0.007770  0.005629  0.010226   \n",
       "909   0.065574  0.022222  0.001355  ...  0.004538  0.005114  0.002429   \n",
       "7649  0.016393  0.005556  0.000000  ...  0.005783  0.002042  0.007231   \n",
       "3903  0.131148  0.072222  0.013550  ...  0.004058  0.001030  0.006124   \n",
       "5385  0.180328  0.072222  0.017615  ...  0.000908  0.001679  0.001254   \n",
       "\n",
       "         66638     66639     66640  66641     66642     66643     66644  \n",
       "4807  0.010028  0.003931  0.003401    0.0  0.034420  0.000489  0.024073  \n",
       "909   0.003818  0.002409  0.000510    0.0  0.016304  0.000000  0.010176  \n",
       "7649  0.003416  0.002476  0.006943    0.0  0.041667  0.004618  0.015210  \n",
       "3903  0.000824  0.008390  0.003427    0.0  0.012681  0.000000  0.021337  \n",
       "5385  0.004803  0.001255  0.003452    0.0  0.021739  0.000000  0.004267  \n",
       "\n",
       "[5 rows x 66646 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing a dictionary where each key is feature number and value is \n",
    "- the number of times it's feature importance is greater than one for all models\n",
    "- the sum of feature importances across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count={}\n",
    "featureimportances_sum={}\n",
    "\n",
    "for i in range(0,66645):\n",
    "    feature_count[str(i)]=0\n",
    "    featureimportances_sum[str(i)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Sample No. 1 ----------------\n",
      "{'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 10}\n",
      "Train Logloss for model on sample no. 1 is 0.08693188083867316\n",
      "CV Logloss for model on sample no. 1 is 0.22614208635596778\n",
      "Test Logloss for model on sample no. 1 is 0.3037386116046462 \n",
      "\n",
      "Logloss on treating other samples as test data is:  0.3376385517697295 \n",
      "\n",
      "----------------Sample No. 2 ----------------\n",
      "{'n_estimators': 2000, 'min_samples_split': 4, 'max_depth': 3}\n",
      "Train Logloss for model on sample no. 2 is 0.7891394455788866\n",
      "CV Logloss for model on sample no. 2 is 0.881235732531081\n",
      "Test Logloss for model on sample no. 2 is 0.915929471312762 \n",
      "\n",
      "Logloss on treating other samples as test data is:  0.9180803807344485 \n",
      "\n",
      "----------------Sample No. 3 ----------------\n",
      "{'n_estimators': 1000, 'min_samples_split': 2, 'max_depth': 5}\n",
      "Train Logloss for model on sample no. 3 is 0.34033763119488675\n",
      "CV Logloss for model on sample no. 3 is 0.527963441295471\n",
      "Test Logloss for model on sample no. 3 is 0.5790812625728627 \n",
      "\n",
      "Logloss on treating other samples as test data is:  0.5026307657616963 \n",
      "\n",
      "----------------Sample No. 4 ----------------\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 10}\n",
      "Train Logloss for model on sample no. 4 is 0.09124212471674602\n",
      "CV Logloss for model on sample no. 4 is 0.2763822470165619\n",
      "Test Logloss for model on sample no. 4 is 1.4160784231595436 \n",
      "\n",
      "Logloss on treating other samples as test data is:  0.4541770253894429 \n",
      "\n",
      "----------------Sample No. 5 ----------------\n",
      "{'n_estimators': 1000, 'min_samples_split': 2, 'max_depth': 10}\n",
      "Train Logloss for model on sample no. 5 is 0.10231352100912512\n",
      "CV Logloss for model on sample no. 5 is 0.3882553013210928\n",
      "Test Logloss for model on sample no. 5 is 0.3332972496384561 \n",
      "\n",
      "Logloss on treating other samples as test data is:  0.37131115467291304 \n",
      "\n",
      "----------------Sample No. 6 ----------------\n",
      "{'n_estimators': 1000, 'min_samples_split': 3, 'max_depth': 10}\n",
      "Train Logloss for model on sample no. 6 is 0.09734935478869754\n",
      "CV Logloss for model on sample no. 6 is 0.4264765452136618\n",
      "Test Logloss for model on sample no. 6 is 0.34903931640961944 \n",
      "\n",
      "Logloss on treating other samples as test data is:  0.3217331248929265 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x,dataset in enumerate(samples):\n",
    "    #train test splitting\n",
    "    print(\"----------------Sample No.\",x+1,\"----------------\")\n",
    "    result_y=dataset['Class']\n",
    "    dataset=dataset.drop(['Class'],axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, result_y,stratify=result_y,test_size=0.20)\n",
    "    X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train,stratify=y_train,test_size=0.20)\n",
    "    \n",
    "    clf=RandomForestClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    usefulfeatures=[]\n",
    "    for i,j in enumerate(clf.feature_importances_):\n",
    "        if j>0:\n",
    "            usefulfeatures.append(str(i))\n",
    "    X_train=X_train[usefulfeatures]\n",
    "    X_cv=X_cv[usefulfeatures]\n",
    "    X_test=X_test[usefulfeatures]\n",
    "    \n",
    "    #using Randomized Search to find best parameters\n",
    "    clf=RandomForestClassifier()\n",
    "    prams={\n",
    "     'n_estimators':[100,200,500,1000,2000],\n",
    "     'max_depth':[3,5,10],\n",
    "    'min_samples_split':[2,3,4]\n",
    "    }\n",
    "    random_cfl=RandomizedSearchCV(clf,param_distributions=prams,n_jobs=-1,)\n",
    "    random_cfl.fit(X_train, y_train)\n",
    "    \n",
    "    print(random_cfl.best_params_)\n",
    "    \n",
    "    #using best parameters and fitting a model on it\n",
    "    clf=RandomForestClassifier(n_estimators=random_cfl.best_params_['n_estimators'],\\\n",
    "                               max_depth=random_cfl.best_params_['max_depth'],\\\n",
    "                               min_samples_split=random_cfl.best_params_['min_samples_split'])\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"Train Logloss for model on sample no.\",x+1,\"is\",log_loss(y_train,clf.predict_proba(X_train)))\n",
    "    print(\"CV Logloss for model on sample no.\",x+1,\"is\",log_loss(y_cv,clf.predict_proba(X_cv)))\n",
    "    print(\"Test Logloss for model on sample no.\",x+1,\"is\",log_loss(y_test,clf.predict_proba(X_test)),\"\\n\")\n",
    "    \n",
    "    #Logloss on treating other samples as test data\n",
    "    loglossonsamples=0\n",
    "    for i in range(0,6):\n",
    "        if x==i:\n",
    "            continue\n",
    "        loglossonsamples+=log_loss(samples[i]['Class'],clf.predict_proba(samples[i][usefulfeatures]))\n",
    "    loglossonsamples/=5\n",
    "    print(\"Logloss on treating other samples as test data is: \",loglossonsamples,\"\\n\")\n",
    "    \n",
    "    for i,j in enumerate(clf.feature_importances_):\n",
    "        feature_count[usefulfeatures[i]]+=j\n",
    "        featureimportances_sum[usefulfeatures[i]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureimportances_sum_array=np.zeros(66645)\n",
    "\n",
    "for i in range(0,66645):\n",
    "    featureimportances_sum_array[i]=featureimportances_sum[str(i)]\n",
    "featureimportances_sum_array.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count_array=np.zeros(66645)\n",
    "\n",
    "for i in range(0,66645):\n",
    "    feature_count_array[i]=feature_count[str(i)]\n",
    "feature_count_array.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. of features with Non-Zero feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6195"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.nonzero(featureimportances_sum_array)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional way of Random Forest Feature Selection\n",
    "- Fit a model onto a sample of data\n",
    "- Select features on basis of feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we already have 6 samples, let's fit model on one of the sample\n",
    "dataset=samples[3]\n",
    "\n",
    "result_y=dataset['Class']\n",
    "dataset=dataset.drop(['Class'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, result_y,stratify=result_y,test_size=0.20)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train,stratify=y_train,test_size=0.20)\n",
    "    \n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traditional_way_importance={}\n",
    "for i,j in enumerate(clf.feature_importances_):\n",
    "    traditional_way_importance[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "traditional_way_importance_array=np.zeros(66645)\n",
    "\n",
    "for i in range(0,66645):\n",
    "    traditional_way_importance_array[i]=traditional_way_importance[i]\n",
    "traditional_way_importance_array.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1366"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.nonzero(traditional_way_importance_array)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Feature Importances\n",
    "- Obtained by fitting model onto 60% of whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the real feature importances\n",
    "realfeatureimportances=pickle.load(open(\"featureimportances\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "realfeatureimportances_array=np.zeros(66645)\n",
    "for i in range(0,66645):\n",
    "    realfeatureimportances_array[i]=realfeatureimportances[i]\n",
    "realfeatureimportances_array.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19882"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.nonzero(realfeatureimportances_array)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many of the features with importance more than zero are important when we consider the whole dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2854 features from our samples are present in the real model\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "for i in realfeatureimportances:\n",
    "    if featureimportances_sum[str(i)]>0:\n",
    "        if realfeatureimportances[i]>0:\n",
    "            correct+=1\n",
    "print(correct,\"features from our samples are present in the real model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751 features from samples in traditional way are present in the real model\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "for i in realfeatureimportances:\n",
    "    if traditional_way_importance[i]>0:\n",
    "        if realfeatureimportances[i]>0:\n",
    "            correct+=1\n",
    "print(correct,\"features from samples in traditional way are present in the real model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of top 500 features\n",
    "- How many of the top 500 features are present in top 500 features of real model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summation of feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of our selected features in top 500 features of real model:  123\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "for i in realfeatureimportances:\n",
    "    if realfeatureimportances[i]>=realfeatureimportances_array[-500]:\n",
    "        if featureimportances_sum[str(i)]>featureimportances_sum_array[-500]:\n",
    "            correct+=1\n",
    "print(\"No. of our selected features in top 500 features of real model: \",correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of our selected features in top 500 features of real model:  220\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "for i in realfeatureimportances:\n",
    "    if realfeatureimportances[i]>=realfeatureimportances_array[-500]:\n",
    "        if feature_count[str(i)]>feature_count_array[-500]:\n",
    "            correct+=1\n",
    "print(\"No. of our selected features in top 500 features of real model: \",correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of our selected features in top 500 features of real model:  116\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "for i in realfeatureimportances:\n",
    "    if realfeatureimportances[i]>=realfeatureimportances_array[-500]:\n",
    "        if traditional_way_importance[i]>traditional_way_importance_array[-500]:\n",
    "            correct+=1\n",
    "print(\"No. of our selected features in top 500 features of real model: \",correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
